{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\nfrom PIL import Image\nfrom IPython.display import display \nimport random\nimport tensorflow as tf","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-15T10:32:04.360883Z","iopub.execute_input":"2023-03-15T10:32:04.361296Z","iopub.status.idle":"2023-03-15T10:32:04.367509Z","shell.execute_reply.started":"2023-03-15T10:32:04.361263Z","shell.execute_reply":"2023-03-15T10:32:04.366380Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_list = pd.read_csv('../input/state-farm-distracted-driver-detection/driver_imgs_list.csv')\nimg_list","metadata":{"execution":{"iopub.status.busy":"2023-03-15T10:32:04.377651Z","iopub.execute_input":"2023-03-15T10:32:04.378645Z","iopub.status.idle":"2023-03-15T10:32:04.417017Z","shell.execute_reply.started":"2023-03-15T10:32:04.378603Z","shell.execute_reply":"2023-03-15T10:32:04.416035Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"      subject classname            img\n0        p002        c0  img_44733.jpg\n1        p002        c0  img_72999.jpg\n2        p002        c0  img_25094.jpg\n3        p002        c0  img_69092.jpg\n4        p002        c0  img_92629.jpg\n...       ...       ...            ...\n22419    p081        c9  img_56936.jpg\n22420    p081        c9  img_46218.jpg\n22421    p081        c9  img_25946.jpg\n22422    p081        c9  img_67850.jpg\n22423    p081        c9   img_9684.jpg\n\n[22424 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject</th>\n      <th>classname</th>\n      <th>img</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>p002</td>\n      <td>c0</td>\n      <td>img_44733.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>p002</td>\n      <td>c0</td>\n      <td>img_72999.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>p002</td>\n      <td>c0</td>\n      <td>img_25094.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>p002</td>\n      <td>c0</td>\n      <td>img_69092.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>p002</td>\n      <td>c0</td>\n      <td>img_92629.jpg</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>22419</th>\n      <td>p081</td>\n      <td>c9</td>\n      <td>img_56936.jpg</td>\n    </tr>\n    <tr>\n      <th>22420</th>\n      <td>p081</td>\n      <td>c9</td>\n      <td>img_46218.jpg</td>\n    </tr>\n    <tr>\n      <th>22421</th>\n      <td>p081</td>\n      <td>c9</td>\n      <td>img_25946.jpg</td>\n    </tr>\n    <tr>\n      <th>22422</th>\n      <td>p081</td>\n      <td>c9</td>\n      <td>img_67850.jpg</td>\n    </tr>\n    <tr>\n      <th>22423</th>\n      <td>p081</td>\n      <td>c9</td>\n      <td>img_9684.jpg</td>\n    </tr>\n  </tbody>\n</table>\n<p>22424 rows Ã— 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"img_directory = '../input/state-farm-distracted-driver-detection/imgs/train'\nimg_directory_test = '../input/state-farm-distracted-driver-detection/imgs/test'","metadata":{"execution":{"iopub.status.busy":"2023-03-15T10:32:04.418574Z","iopub.execute_input":"2023-03-15T10:32:04.418965Z","iopub.status.idle":"2023-03-15T10:32:04.423663Z","shell.execute_reply.started":"2023-03-15T10:32:04.418931Z","shell.execute_reply":"2023-03-15T10:32:04.422608Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# 4:3 ratio images at 640x480, we'll scale it down to make it easier for the network\ntrain_ds = tf.keras.utils.image_dataset_from_directory(img_directory,validation_split=0.2 ,subset=\"training\",seed=123, image_size =(256,192), batch_size=32)\nval_ds = tf.keras.utils.image_dataset_from_directory(img_directory,validation_split=0.2 ,subset=\"validation\",seed=123, image_size =(256,192), batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2023-03-15T10:32:04.426652Z","iopub.execute_input":"2023-03-15T10:32:04.426993Z","iopub.status.idle":"2023-03-15T10:32:22.606235Z","shell.execute_reply.started":"2023-03-15T10:32:04.426959Z","shell.execute_reply":"2023-03-15T10:32:22.605084Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Found 22424 files belonging to 10 classes.\nUsing 17940 files for training.\nFound 22424 files belonging to 10 classes.\nUsing 4484 files for validation.\n","output_type":"stream"}]},{"cell_type":"code","source":"def create_model(input_dims, output_dims):\n    with tf.name_scope(\"cnn\"):\n        model = tf.keras.Sequential()\n        model.add(tf.keras.layers.InputLayer(input_shape=input_dims))\n        model.add(tf.keras.layers.Rescaling(1./255))\n        model.add(tf.keras.layers.Conv2D(32,3, activation=\"relu\"))\n        model.add(tf.keras.layers.MaxPooling2D())\n        model.add(tf.keras.layers.Conv2D(64,3, activation=\"relu\"))\n        model.add(tf.keras.layers.MaxPooling2D())\n        model.add(tf.keras.layers.Conv2D(128,3,activation=\"relu\"))\n        model.add(tf.keras.layers.Flatten())\n        \n        #fully connected layer\n        model.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n        model.add(tf.keras.layers.Dense(64, activation=\"relu\"))\n        model.add(tf.keras.layers.Dense(output_dims, activation=\"softmax\"))\n        \n        model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=['accuracy'])\n        \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-03-15T10:32:22.607778Z","iopub.execute_input":"2023-03-15T10:32:22.608406Z","iopub.status.idle":"2023-03-15T10:32:22.619523Z","shell.execute_reply.started":"2023-03-15T10:32:22.608363Z","shell.execute_reply":"2023-03-15T10:32:22.618532Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"model = create_model([256,192,3], 10)","metadata":{"execution":{"iopub.status.busy":"2023-03-15T10:32:22.621211Z","iopub.execute_input":"2023-03-15T10:32:22.621973Z","iopub.status.idle":"2023-03-15T10:32:22.697131Z","shell.execute_reply.started":"2023-03-15T10:32:22.621913Z","shell.execute_reply":"2023-03-15T10:32:22.696242Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-03-15T10:32:22.699267Z","iopub.execute_input":"2023-03-15T10:32:22.699839Z","iopub.status.idle":"2023-03-15T10:32:22.707572Z","shell.execute_reply.started":"2023-03-15T10:32:22.699804Z","shell.execute_reply":"2023-03-15T10:32:22.706109Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nrescaling_1 (Rescaling)      (None, 256, 192, 3)       0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 254, 190, 32)      896       \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 127, 95, 32)       0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 125, 93, 64)       18496     \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 62, 46, 64)        0         \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 60, 44, 128)       73856     \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 337920)            0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 128)               43253888  \n_________________________________________________________________\ndense_4 (Dense)              (None, 64)                8256      \n_________________________________________________________________\ndense_5 (Dense)              (None, 10)                650       \n=================================================================\nTotal params: 43,356,042\nTrainable params: 43,356,042\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"EPOCHS = 25\n\nhistory = model.fit(train_ds, epochs=EPOCHS, validation_data=val_ds)","metadata":{"execution":{"iopub.status.busy":"2023-03-15T10:32:22.709461Z","iopub.execute_input":"2023-03-15T10:32:22.709992Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/25\n561/561 [==============================] - 64s 113ms/step - loss: 0.4618 - accuracy: 0.8495 - val_loss: 0.0710 - val_accuracy: 0.9799\nEpoch 2/25\n561/561 [==============================] - 61s 108ms/step - loss: 0.0316 - accuracy: 0.9906 - val_loss: 0.0330 - val_accuracy: 0.9917\nEpoch 3/25\n561/561 [==============================] - 62s 109ms/step - loss: 0.0245 - accuracy: 0.9933 - val_loss: 0.0692 - val_accuracy: 0.9786\nEpoch 4/25\n561/561 [==============================] - 59s 104ms/step - loss: 0.0105 - accuracy: 0.9975 - val_loss: 0.0236 - val_accuracy: 0.9944\nEpoch 5/25\n561/561 [==============================] - 61s 107ms/step - loss: 0.0148 - accuracy: 0.9963 - val_loss: 0.0495 - val_accuracy: 0.9884\nEpoch 6/25\n561/561 [==============================] - 59s 104ms/step - loss: 0.0240 - accuracy: 0.9928 - val_loss: 0.0439 - val_accuracy: 0.9895\nEpoch 7/25\n561/561 [==============================] - 60s 105ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.0247 - val_accuracy: 0.9949\nEpoch 8/25\n561/561 [==============================] - 59s 105ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0190 - val_accuracy: 0.9960\nEpoch 9/25\n561/561 [==============================] - 59s 105ms/step - loss: 3.7376e-05 - accuracy: 1.0000 - val_loss: 0.0208 - val_accuracy: 0.9960\nEpoch 10/25\n561/561 [==============================] - 59s 104ms/step - loss: 3.9632e-06 - accuracy: 1.0000 - val_loss: 0.0211 - val_accuracy: 0.9960\nEpoch 11/25\n561/561 [==============================] - 59s 104ms/step - loss: 2.0216e-06 - accuracy: 1.0000 - val_loss: 0.0213 - val_accuracy: 0.9964\nEpoch 12/25\n561/561 [==============================] - 60s 106ms/step - loss: 1.2736e-06 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 0.9964\nEpoch 13/25\n561/561 [==============================] - 59s 105ms/step - loss: 8.5413e-07 - accuracy: 1.0000 - val_loss: 0.0217 - val_accuracy: 0.9964\nEpoch 14/25\n561/561 [==============================] - 60s 106ms/step - loss: 5.9283e-07 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 0.9964\nEpoch 15/25\n561/561 [==============================] - 70s 124ms/step - loss: 4.2028e-07 - accuracy: 1.0000 - val_loss: 0.0221 - val_accuracy: 0.9964\nEpoch 16/25\n561/561 [==============================] - 60s 105ms/step - loss: 3.0413e-07 - accuracy: 1.0000 - val_loss: 0.0223 - val_accuracy: 0.9964\nEpoch 17/25\n561/561 [==============================] - 59s 105ms/step - loss: 2.2284e-07 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 0.9964\nEpoch 18/25\n561/561 [==============================] - 59s 105ms/step - loss: 1.6459e-07 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 0.9964\nEpoch 19/25\n561/561 [==============================] - 59s 105ms/step - loss: 1.2240e-07 - accuracy: 1.0000 - val_loss: 0.0230 - val_accuracy: 0.9964\nEpoch 20/25\n561/561 [==============================] - 60s 105ms/step - loss: 9.1374e-08 - accuracy: 1.0000 - val_loss: 0.0232 - val_accuracy: 0.9964\nEpoch 21/25\n561/561 [==============================] - 60s 106ms/step - loss: 6.8542e-08 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 0.9964\nEpoch 22/25\n561/561 [==============================] - 59s 105ms/step - loss: 5.1804e-08 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 0.9964\nEpoch 23/25\n104/561 [====>.........................] - ETA: 42s - loss: 5.3766e-08 - accuracy: 1.0000","output_type":"stream"}]},{"cell_type":"code","source":"print(sum(history.history['accuracy']) / EPOCHS)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.plot(history.history['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}